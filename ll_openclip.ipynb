{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee8f09a-40c5-4e52-bb46-75dc38d96a05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import DQN\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is \", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741daef3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.disable_view_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03579506-1dc0-4fbe-b6d8-b9bc6ad250fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CLIPEnv(object):\n",
    "    def __init__(self, env, clip_model: open_clip.model.CLIP, clip_preprocess, tokenizer, prompts, writer, prompt_ensemble_strategy=\"max\"):\n",
    "        self.env = env\n",
    "\n",
    "        self.model = clip_model\n",
    "        self.preprocess = clip_preprocess\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.text_features = self.model.encode_text(self.tokenizer(prompts).to(device))\n",
    "        self.text_features /= self.text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        self.action_space = self.env.action_space\n",
    "        self.observation_space = self.env.observation_space\n",
    "        self.metadata = self.env.metadata\n",
    "\n",
    "        self.prompts_ensemble_strategy = prompt_ensemble_strategy\n",
    "\n",
    "        self.clip_rewards_per_episode = []\n",
    "        self.env_rewards_per_episode = []\n",
    "\n",
    "        self.clip_rewards = []\n",
    "        self.env_rewards = []\n",
    "\n",
    "        self.writer = writer\n",
    "        self.n_steps = 0\n",
    "        self.n_episodes = 0\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def close(self):\n",
    "        return self.env.close()\n",
    "\n",
    "    def step(self, action):\n",
    "        next_st, rwd, done, info = self.env.step(action)\n",
    "        img = self.env.render(mode=\"rgb_array\")\n",
    "        clip_rwd = self.get_clip_reward(img)\n",
    "\n",
    "        self.env_rewards_per_episode.append(rwd)\n",
    "        self.clip_rewards_per_episode.append(clip_rwd)\n",
    "\n",
    "        if done:\n",
    "            self.writer.add_scalar('episode_rewards/env_reward',  sum(self.env_rewards_per_episode), self.n_episodes)\n",
    "            self.writer.add_scalar('episode_rewards/clip_reward', sum(self.clip_rewards_per_episode) , self.n_episodes)\n",
    "\n",
    "            self.env_rewards.append(self.env_rewards_per_episode)\n",
    "            self.clip_rewards.append(self.clip_rewards_per_episode)\n",
    "\n",
    "            self.env_rewards_per_episode = []\n",
    "            self.clip_rewards_per_episode = []\n",
    "\n",
    "            self.n_episodes += 1\n",
    "\n",
    "        self.n_steps += 1\n",
    "\n",
    "        return next_st, rwd, done, info\n",
    "\n",
    "    def get_clip_reward(self, state):\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            image = self.preprocess(Image.fromarray(np.uint8(state)))\n",
    "            image_features = self.model.encode_image(image.unsqueeze(0).to(device))\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "            sim = (image_features @ self.text_features.T)\n",
    "        sim = sim.cpu().detach().numpy()\n",
    "        if self.prompts_ensemble_strategy == \"max\":\n",
    "            return np.amax(sim[0])\n",
    "        elif self.prompts_ensemble_strategy == \"sum\":\n",
    "            return np.sum(sim[0])\n",
    "        else:  # mean\n",
    "            return np.mean(sim[0])\n",
    "\n",
    "    @property\n",
    "    def unwrapped(self):\n",
    "        return self.env.unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9f0393-6e67-4f26-a621-603a1a731dd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘experiments’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def run_exp(agent, env, prompts, clip_model_name, env_name, exp_path, n_steps, notes=''):\n",
    "    if not os.path.exists(exp_path):\n",
    "        os.mkdir(exp_path)\n",
    "\n",
    "\n",
    "    agent.learn(total_timesteps=n_steps, progress_bar=True)\n",
    "    agent.save(f\"{exp_path}/agent\")\n",
    "\n",
    "    corr = stats.pearsonr([sum(e) for e in env.env_rewards], [sum(e) for e in env.clip_rewards])[0]\n",
    "    m_rwd = np.mean([sum(e) for e in env.env_rewards[-10:]])\n",
    "    results = {\n",
    "        'env_name': env_name,\n",
    "        'prompt': prompts,\n",
    "        'clip_model_name': clip_model_name,\n",
    "        'correlation': corr,\n",
    "        'mean_env_rwd_over_last_10_episodes': m_rwd,\n",
    "        'n_episodes': env.n_episodes,\n",
    "        'n_steps': env.n_steps,\n",
    "         'notes': notes,\n",
    "    }\n",
    "    with open(f'{exp_path}/results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    # compute correlation between env and clip rewards for each episode separately\n",
    "    per_episode_corr = [stats.pearsonr(e, c)[0] for e, c in zip(env.env_rewards, env.clip_rewards)]\n",
    "    for i in range(env.n_episodes):\n",
    "        env.writer.add_scalar('Per episode correlation', per_episode_corr[i], i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17a577c-3f55-40cc-9730-9e80b721dd83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load CLIP\n",
    "clip_model, _, clip_preprocess = open_clip.create_model_and_transforms('ViT-B-32-quickgelu', pretrained='laion400m_e32')\n",
    "clip_tokenizer = open_clip.get_tokenizer('ViT-B-32-quickgelu')\n",
    "clip_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Launch TensorBoard in Google Colab\n",
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "%tensorboard --logdir /content/experiments/first_run/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OR alternatively launch TensorBoard on your local machine\n",
    "!tensorboard --logdir 'experiments/first_run/' --host 0.0.0.0 --port 6006"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21621cb-7d5d-4ed0-8ceb-d2d1b2415ef9",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[?25l",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "096ad97ec7b14d00b94d2614b40b8e62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\r\u001B[2KC:\\Users\\IronTony\\miniconda3\\envs\\ani\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:406: UserWarning: [WinError \n-2147417850] Cannot change thread mode after it is set\n  warnings.warn(str(err))\n\u001B[35m   0%\u001B[0m \u001B[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0/20,000 \u001B[0m [ \u001B[33m0:00:00\u001B[0m < \u001B[36m-:--:--\u001B[0m , \u001B[31m? it/s\u001B[0m ]",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\r\u001B[2KC:\\Users\\IronTony\\miniconda3\\envs\\ani\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:406: UserWarning: [WinError \n-2147417850] Cannot change thread mode after it is set\n  warnings.warn(str(err))\n<span style=\"color: #800080; text-decoration-color: #800080\">   0%</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">0/20,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\r\u001B[2KC:\\Users\\IronTony\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\amp\\autocast_mode.py:202: UserWarning: User provided \ndevice_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n\u001B[35m   0%\u001B[0m \u001B[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0/20,000 \u001B[0m [ \u001B[33m0:00:00\u001B[0m < \u001B[36m-:--:--\u001B[0m , \u001B[31m? it/s\u001B[0m ]",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\r\u001B[2KC:\\Users\\IronTony\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\amp\\autocast_mode.py:202: UserWarning: User provided \ndevice_type of 'cuda', but CUDA is not available. Disabling\n  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n<span style=\"color: #800080; text-decoration-color: #800080\">   0%</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">0/20,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span> , <span style=\"color: #800000; text-decoration-color: #800000\">? it/s</span> ]</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m cl_env \u001B[38;5;241m=\u001B[39m CLIPEnv(env, clip_model, clip_preprocess, clip_tokenizer, prompts, writer)\n\u001B[0;32m     11\u001B[0m agent \u001B[38;5;241m=\u001B[39m DQN(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMlpPolicy\u001B[39m\u001B[38;5;124m'\u001B[39m, cl_env, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, learning_starts\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, buffer_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15000\u001B[39m, target_update_interval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m \u001B[43mrun_exp\u001B[49m\u001B[43m(\u001B[49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcl_env\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mopen_clip_ViT-B-32-quickgelu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mENV_NAME\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEXP_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_STEPS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mall additional info about experiment goes here\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [5], line 6\u001B[0m, in \u001B[0;36mrun_exp\u001B[1;34m(agent, env, prompts, clip_model_name, env_name, exp_path, n_steps, notes)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(exp_path):\n\u001B[0;32m      3\u001B[0m     os\u001B[38;5;241m.\u001B[39mmkdir(exp_path)\n\u001B[1;32m----> 6\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m agent\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexp_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/agent\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m corr \u001B[38;5;241m=\u001B[39m stats\u001B[38;5;241m.\u001B[39mpearsonr([\u001B[38;5;28msum\u001B[39m(e) \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m env\u001B[38;5;241m.\u001B[39menv_rewards], [\u001B[38;5;28msum\u001B[39m(e) \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m env\u001B[38;5;241m.\u001B[39mcloob_rewards])[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:275\u001B[0m, in \u001B[0;36mDQN.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28mself\u001B[39m: DQNSelf,\n\u001B[0;32m    263\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    272\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    273\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DQNSelf:\n\u001B[1;32m--> 275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_eval_episodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_eval_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_log_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_log_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:356\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.learn\u001B[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[0;32m    353\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_start(\u001B[38;5;28mlocals\u001B[39m(), \u001B[38;5;28mglobals\u001B[39m())\n\u001B[0;32m    355\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[1;32m--> 356\u001B[0m     rollout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    357\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    359\u001B[0m \u001B[43m        \u001B[49m\u001B[43maction_noise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maction_noise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    361\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlearning_starts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    362\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    363\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rollout\u001B[38;5;241m.\u001B[39mcontinue_training \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    367\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:589\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.collect_rollouts\u001B[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001B[0m\n\u001B[0;32m    586\u001B[0m actions, buffer_actions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sample_action(learning_starts, action_noise, env\u001B[38;5;241m.\u001B[39mnum_envs)\n\u001B[0;32m    588\u001B[0m \u001B[38;5;66;03m# Rescale and perform action\u001B[39;00m\n\u001B[1;32m--> 589\u001B[0m new_obs, rewards, dones, infos \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mnum_envs\n\u001B[0;32m    592\u001B[0m num_collected_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:162\u001B[0m, in \u001B[0;36mVecEnv.step\u001B[1;34m(self, actions)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03mStep the environments with the given action\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \n\u001B[0;32m    158\u001B[0m \u001B[38;5;124;03m:param actions: the action\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m:return: observation, reward, done, information\u001B[39;00m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_async(actions)\n\u001B[1;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:43\u001B[0m, in \u001B[0;36mDummyVecEnv.step_wait\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep_wait\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m VecEnvStepReturn:\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m env_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_envs):\n\u001B[1;32m---> 43\u001B[0m         obs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_rews[env_idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactions\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_dones[env_idx]:\n\u001B[0;32m     47\u001B[0m             \u001B[38;5;66;03m# save final observation where user can get it, then reset\u001B[39;00m\n\u001B[0;32m     48\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuf_infos[env_idx][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mterminal_observation\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m obs\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001B[0m, in \u001B[0;36mMonitor.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneeds_reset:\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTried to step environment that needs reset\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 94\u001B[0m observation, reward, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrewards\u001B[38;5;241m.\u001B[39mappend(reward)\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n",
      "Cell \u001B[1;32mIn [3], line 35\u001B[0m, in \u001B[0;36mCLIPEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     33\u001B[0m next_st, rwd, done, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[0;32m     34\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mrender(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrgb_array\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 35\u001B[0m clip_rwd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_clip_reward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv_rewards_per_episode\u001B[38;5;241m.\u001B[39mappend(rwd)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclip_rewards_per_episode\u001B[38;5;241m.\u001B[39mappend(clip_rwd)\n",
      "Cell \u001B[1;32mIn [3], line 59\u001B[0m, in \u001B[0;36mCLIPEnv.get_clip_reward\u001B[1;34m(self, state)\u001B[0m\n\u001B[0;32m     57\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(Image\u001B[38;5;241m.\u001B[39mfromarray(np\u001B[38;5;241m.\u001B[39muint8(state)))\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad(), torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast():\n\u001B[1;32m---> 59\u001B[0m     image_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m     image_features \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m image_features\u001B[38;5;241m.\u001B[39mnorm(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     61\u001B[0m     sim \u001B[38;5;241m=\u001B[39m (image_features \u001B[38;5;241m@\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_features\u001B[38;5;241m.\u001B[39mT)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\open_clip\\model.py:182\u001B[0m, in \u001B[0;36mCLIP.encode_image\u001B[1;34m(self, image, normalize)\u001B[0m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode_image\u001B[39m(\u001B[38;5;28mself\u001B[39m, image, normalize: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m--> 182\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mnormalize(features, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m normalize \u001B[38;5;28;01melse\u001B[39;00m features\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\open_clip\\transformer.py:314\u001B[0m, in \u001B[0;36mVisionTransformer.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    311\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_pre(x)\n\u001B[0;32m    313\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# NLD -> LND\u001B[39;00m\n\u001B[1;32m--> 314\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    315\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# LND -> NLD\u001B[39;00m\n\u001B[0;32m    317\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_post(x[:, \u001B[38;5;241m0\u001B[39m, :])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\open_clip\\transformer.py:230\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[1;34m(self, x, attn_mask)\u001B[0m\n\u001B[0;32m    228\u001B[0m         x \u001B[38;5;241m=\u001B[39m checkpoint(r, x, attn_mask)\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 230\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\open_clip\\transformer.py:155\u001B[0m, in \u001B[0;36mResidualAttentionBlock.forward\u001B[1;34m(self, x, attn_mask)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor, attn_mask: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    154\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mls_1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_1(x), attn_mask\u001B[38;5;241m=\u001B[39mattn_mask))\n\u001B[1;32m--> 155\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mls_2(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mln_2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ani\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EXP_PATH = 'experiments/first_run/'\n",
    "ENV_NAME = 'LunarLander-v2'\n",
    "N_STEPS = 20000\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "prompts = ['Spaceship is on the landing pad', 'The purple box is between two yellow triangles and is touching the white surface.']\n",
    "writer = SummaryWriter(EXP_PATH)\n",
    "\n",
    "cl_env = CLIPEnv(env, clip_model, clip_preprocess, clip_tokenizer, prompts, writer)\n",
    "\n",
    "agent = DQN('MlpPolicy', cl_env, verbose=0, learning_starts=1000, buffer_size=15000, target_update_interval=500)\n",
    "run_exp(agent, cl_env, prompts, 'open_clip_ViT-B-32-quickgelu', ENV_NAME, EXP_PATH, N_STEPS,\n",
    "        'all additional info about experiment goes here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de59dde-4c54-4fed-8a9b-bae872c2963d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecbc0d6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment_prompt(prompt, agent, env, rewards_storage, n_steps=100):\n",
    "    obs = env.reset()\n",
    "    for _ in range(n_steps):\n",
    "        action, _states = agent.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "    rewards_storage[prompt] = (env.env_rewards.copy(), env.clip_rewards.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc05740-9474-425e-94ce-819df6f2b9b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prompt_rewards = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c86a592a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EXP_PATH = 'experiments/first_run/'\n",
    "env = gym.make('LunarLander-v2')\n",
    "cl_env = CLIPEnv(env, clip_model, clip_preprocess, clip_tokenizer, prompts, writer)\n",
    "prompt = 'Spaceship is on the landing pad'\n",
    "\n",
    "agent = DQN.load(f\"{EXP_PATH}/agent\", env=cl_env)\n",
    "experiment_prompt(prompt, agent, cl_env, prompt_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1433b31e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cl_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "178115d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Env rewards (1 episode)')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prompt_rewards[prompt][0][0])\n",
    "plt.title('Env rewards (1 episode)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d6fbeff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CLIP rewards (1 episode)')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prompt_rewards[prompt][1][0])\n",
    "plt.title('CLIP rewards (1 episode)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "af2b1c113fb30453ab0f38cb28889d45a8255f9a09eebc90dd674ef9d0f3b315"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}